{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating the VLAAI network proposed in [Accurate decoding of the speech envelope using the VLAAI deep neural network](./#) on the DTU dataset.\n",
    "\n",
    "In this example, a pre-trained VLAAI network will be evaluated on the publicly available dataset from [Fuglsang et al.](https://zenodo.org/record/1199011). This dataset contains 18 subjects who listened to one of two competing speech audio streams of 50 seconds with different levels of reverberation. For this example, we will only take the single-speaker trials (approximately 10 per subject, 500 seconds in total) into account.\n",
    "\n",
    "The preprocessing used in this notebook is the same as proposed in the [paper](./#):\n",
    "* For __EEG__: \n",
    "  1. High-pass filtering using a 1st order Butterworth filter with a cutoff frequency of 0.5Hz\n",
    "  2. Downsampling to 1024 Hz\n",
    "  3. Eyeblink artefact removal using a Multichannel Wiener filter\n",
    "  4. Common average re-referencing\n",
    "  5. Downsampling to 64Hz\n",
    "\n",
    "* For __Speech__:\n",
    "  1. Envelope extraction using a gamma-tone filterbank\n",
    "  2. Downsampling to 1024 Hz\n",
    "  3. Downsampling to 64 Hz\n",
    "\n",
    "Preprocessed versions of the data are included in the [github repository](./#), code to the run the preprocessing manually is coming soon."
   ],
   "metadata": {
    "id": "0Zayka08jFo5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting started\n",
    "\n",
    "Installing the requirements"
   ],
   "metadata": {
    "id": "YCZ6eWP3mk-w"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sycRcpB1pDfB",
    "outputId": "aad8f74d-f95e-4f91-935c-268b65585289"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow==2.10.0\n",
      "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
      "Collecting mne\n",
      "  Downloading mne-1.1.1-py3-none-any.whl (7.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.5 MB 3.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 55.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (3.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.48.1)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 47.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (0.26.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (2.0.7)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (14.0.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (4.1.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (21.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (57.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.14.1)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 47.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.10.0) (1.15.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow==2.10.0) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, tensorflow, mne\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
      "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
      "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
      "Successfully installed gast-0.4.0 keras-2.10.0 mne-1.1.1 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/berndie/vlaai\n",
    "# Install the requirements\n",
    "!pip3 install requirements.txt\n",
    "!cd vlaai"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating the pre-trained VLAAI network on the (already preprocessed) DTU dataset"
   ],
   "metadata": {
    "id": "6v0u3KYbnGxG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# General imports\n",
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import vlaai\n",
    "from examples.utils import window_data\n",
    "from scipy.stats import pearsonr"
   ],
   "metadata": {
    "id": "Z0THqb8oi7cF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "vlaai_model = vlaai()\n",
    "vlaai_model.load_weights(\"pretrained_model/vlaai.h5\")\n",
    "vlaai_model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDtpvlLcpWp7",
    "outputId": "a2e29c1d-c58c-459b-b16f-5afa4ded9a54"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-09-23 14:06:13--  https://zenodo.org/record/1199011/files/EEG.zip\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16044939963 (15G) [application/octet-stream]\n",
      "Saving to: ‘EEG.zip.1’\n",
      "\n",
      "EEG.zip.1           100%[===================>]  14.94G  18.3MB/s    in 17m 45s \n",
      "\n",
      "2022-09-23 14:24:00 (14.4 MB/s) - ‘EEG.zip.1’ saved [16044939963/16044939963]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "paths = glob.glob(\"evaluation_datasets/DTU/*.npz\")\n",
    "print(\"Found {} paths for evaluation\".format(len(paths)))\n",
    "subjects = set([\"_\".join(os.path.basename(x).split(\"_\")[:2]) for x in paths])\n",
    "print(\"Found {} subjects for evaluation\".format(len(subjects)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLEU9HQspf79",
    "outputId": "b814a5b4-8f20-4ae8-e3a1-8d73b8988759"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  EEG.zip\n",
      " extracting: S1.mat                  \n",
      " extracting: S10.mat                 \n",
      " extracting: S11.mat                 \n",
      " extracting: S12.mat                 \n",
      " extracting: S13.mat                 \n",
      " extracting: S14.mat                 \n",
      " extracting: S15.mat                 \n",
      " extracting: S16.mat                 \n",
      " extracting: S17.mat                 \n",
      " extracting: S18.mat                 \n",
      " extracting: S2.mat                  \n",
      " extracting: S3.mat                  \n",
      " extracting: S4.mat                  \n",
      " extracting: S5.mat                  \n",
      " extracting: S6.mat                  \n",
      " extracting: S7.mat                  \n",
      " extracting: S8.mat                  \n",
      " extracting: S9.mat                  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Run the model evaluation\n",
    "subject_scores = {}\n",
    "boxplot_data = []\n",
    "\n",
    "# Iterate over the subjects in the DTU dataset\n",
    "for subject in subjects:\n",
    "    print(\"Evaluating subject {}\".format(subject))\n",
    "    for p in glob.glob(\"evaluation_datasets/DTU/{}_*.npz\".format(subject)):\n",
    "        print(\"Gathering scores for {}...\".format(p))\n",
    "        # Load the data\n",
    "        # Data is stored in .npz format with two keys: 'eeg' and 'envelope'\n",
    "        # containing preprocessed EEG and corresponding speech stimulus\n",
    "        # envelope.\n",
    "        data = np.load(p)\n",
    "        eeg = data[\"eeg\"]\n",
    "        envelope = data[\"envelope\"]\n",
    "\n",
    "        # Standardize EEG and envelope\n",
    "        eeg = (eeg - eeg.mean(axis=0, keepdims=True)) / eeg.std(\n",
    "            axis=0, keepdims=True\n",
    "        )\n",
    "        envelope = (\n",
    "            envelope - envelope.mean(axis=0, keepdims=True)\n",
    "        ) / envelope.std(axis=0, keepdims=True)\n",
    "\n",
    "        # Window the data in windows of 5 seconds with 80% overlap\n",
    "        windowed_eeg = window_data(eeg, 320, 64)\n",
    "        windowed_envelope = window_data(envelope, 320, 64)\n",
    "\n",
    "        # Evaluate the model on the overlapping windows\n",
    "        if subject not in subject_scores:\n",
    "            subject_scores[subject] = []\n",
    "        predictions = vlaai_model.predict(windowed_eeg)\n",
    "        for pred, true in zip(predictions, windowed_envelope):\n",
    "            r = pearsonr(pred.reshape(-1), true.reshape(-1))\n",
    "            subject_scores[subject] += [r[0]]\n",
    "    # Report the mean score for each subject\n",
    "    mean_scores = np.mean(subject_scores[subject])\n",
    "    boxplot_data += [mean_scores]\n",
    "    print(\"Subject {}: {}\".format(subject, mean_scores))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbPLIlKu978e",
    "outputId": "f294047e-46fb-4110-df46-2544bd01aa9c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'data', 'None', '__function_workspace__'])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.boxplot(boxplot_data)\n",
    "plt.ylabel(\"Pearson correlation\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "8qYERJcE-RuL",
    "outputId": "04a988c2-ca75-452f-f797-1c80f034fbb6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e86ded6c0238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'expinfo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: b'expinfo'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COMING SOON: Code to do the preprocessing from scratch"
   ],
   "metadata": {
    "id": "Exg5AVxGqycb"
   }
  }
 ]
}
