{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating the VLAAI network proposed in [Accurate decoding of the speech envelope using the VLAAI deep neural network](./#) on the DTU dataset.\n",
    "\n",
    "In this example, a pre-trained VLAAI network will be evaluated on the publicly available dataset from [Fuglsang et al.](https://zenodo.org/record/1199011). This dataset contains 18 subjects who listened to one of two competing speech audio streams of 50 seconds with different levels of reverberation. For this example, we will only take the single-speaker trials (approximately 10 per subject, 500 seconds in total) into account.\n",
    "\n",
    "The preprocessing used in this notebook is the same as proposed in the [paper](./#):\n",
    "* For __EEG__: \n",
    "  1. High-pass filtering using a 1st order Butterworth filter with a cutoff frequency of 0.5Hz\n",
    "  2. Downsampling to 1024 Hz\n",
    "  3. Eyeblink artefact removal using a Multichannel Wiener filter\n",
    "  4. Common average re-referencing\n",
    "  5. Downsampling to 64Hz\n",
    "\n",
    "* For __Speech__:\n",
    "  1. Envelope extraction using a gamma-tone filterbank\n",
    "  2. Downsampling to 1024 Hz\n",
    "  3. Downsampling to 64 Hz\n",
    "\n",
    "Preprocessed versions of the data are included in the [github repository](./#), code to the run the preprocessing manually is coming soon."
   ],
   "metadata": {
    "id": "0Zayka08jFo5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting started\n",
    "\n",
    "Installing the requirements"
   ],
   "metadata": {
    "id": "YCZ6eWP3mk-w"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sycRcpB1pDfB",
    "outputId": "aad8f74d-f95e-4f91-935c-268b65585289"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/berndie/vlaai\n",
    "%cd vlaai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install the requirements\n",
    "!pip3 install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating the pre-trained VLAAI network on the (already preprocessed) DTU dataset"
   ],
   "metadata": {
    "id": "6v0u3KYbnGxG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# General imports\n",
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "from model import vlaai\n",
    "from examples.utils import window_data\n",
    "from scipy.stats import pearsonr"
   ],
   "metadata": {
    "id": "Z0THqb8oi7cF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "vlaai_model = vlaai()\n",
    "vlaai_model.load_weights(\"pretrained_models/vlaai.h5\")\n",
    "vlaai_model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDtpvlLcpWp7",
    "outputId": "a2e29c1d-c58c-459b-b16f-5afa4ded9a54"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "paths = glob.glob(\"evaluation_datasets/DTU/*.npz\")\n",
    "print(\"Found {} paths for evaluation\".format(len(paths)))\n",
    "subjects = set([\"_\".join(os.path.basename(x).split(\"_\")[:2]) for x in paths])\n",
    "print(\"Found {} subjects for evaluation\".format(len(subjects)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLEU9HQspf79",
    "outputId": "b814a5b4-8f20-4ae8-e3a1-8d73b8988759"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Set the number of trials that should be evaluated on for each subject\n",
    "# If None, it will evaluate on all trials\n",
    "# You can set this to a lower number to speed up the next code cell\n",
    "nb_evaluation_trials = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Run the model evaluation\n",
    "subject_scores = {}\n",
    "boxplot_data = []\n",
    "\n",
    "# Iterate over the subjects in the DTU dataset\n",
    "for subject in subjects:\n",
    "    print(\"Evaluating subject {}\".format(subject))\n",
    "    for index, p in enumerate(\n",
    "        glob.glob(\"evaluation_datasets/DTU/{}_*.npz\".format(subject))\n",
    "    ):\n",
    "        print(\"Gathering scores for {}...\".format(p))\n",
    "        # Load the data\n",
    "        # Data is stored in .npz format with two keys: 'eeg' and 'envelope'\n",
    "        # containing preprocessed EEG and corresponding speech stimulus\n",
    "        # envelope.\n",
    "        data = np.load(p)\n",
    "        eeg = data[\"eeg\"]\n",
    "        envelope = data[\"envelope\"]\n",
    "\n",
    "        # Standardize EEG and envelope\n",
    "        eeg = (eeg - eeg.mean(axis=0, keepdims=True)) / eeg.std(\n",
    "            axis=0, keepdims=True\n",
    "        )\n",
    "        envelope = (\n",
    "            envelope - envelope.mean(axis=0, keepdims=True)\n",
    "        ) / envelope.std(axis=0, keepdims=True)\n",
    "\n",
    "        # Window the data in windows of 5 seconds with 80% overlap\n",
    "        windowed_eeg = window_data(eeg, 320, 64)\n",
    "        windowed_envelope = window_data(envelope, 320, 64)\n",
    "\n",
    "        # Evaluate the model on the overlapping windows\n",
    "        if subject not in subject_scores:\n",
    "            subject_scores[subject] = []\n",
    "        predictions = vlaai_model.predict(windowed_eeg)\n",
    "        for pred, true in zip(predictions, windowed_envelope):\n",
    "            r = pearsonr(pred.reshape(-1), true.reshape(-1))\n",
    "            subject_scores[subject] += [r[0]]\n",
    "        if (\n",
    "            nb_evaluation_trials is not None\n",
    "            and index == nb_evaluation_trials - 1\n",
    "        ):\n",
    "            # Stop at this trial for the current subject\n",
    "            break\n",
    "    # Report the mean score for each subject\n",
    "    mean_scores = np.mean(subject_scores[subject])\n",
    "    boxplot_data += [mean_scores]\n",
    "    print(\"Subject {}: {}\".format(subject, mean_scores))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbPLIlKu978e",
    "outputId": "f294047e-46fb-4110-df46-2544bd01aa9c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "df = pd.DataFrame.from_dict({\"VLAAI network\": boxplot_data})\n",
    "sns.violinplot(data=df, orient=\"v\")\n",
    "plt.ylabel(\"Reconstruction score (Pearson correlation)\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.title(\"Evaluation of the pre-trained VLAAI model on the DTU dataset\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"Median score = {:.2f}\".format(np.median(boxplot_data)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "8qYERJcE-RuL",
    "outputId": "04a988c2-ca75-452f-f797-1c80f034fbb6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COMING SOON: Code to do the preprocessing from scratch"
   ],
   "metadata": {
    "id": "Exg5AVxGqycb"
   }
  }
 ]
}
